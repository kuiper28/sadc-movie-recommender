{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():    \n",
        "    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "SnAUCnMM9ErV",
        "outputId": "8fef852c-53a9-4248-8d7e-447059126e88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For @CRM add yor github token\n",
        "!git clone 'https://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:x-oauth-basic@github.com/kuiper28/sadc-movie-recommender.git'\n",
        "\n",
        "%cd sadc-movie-recommender\n",
        "!git checkout ui-changes\n",
        "%cd rnn_model"
      ],
      "metadata": {
        "id": "ybVwpQjC9MGM",
        "outputId": "7f37907a-b0d8-4e12-a686-36e1511ae952",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sadc-movie-recommender'...\n",
            "remote: Enumerating objects: 76, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 76 (delta 11), reused 23 (delta 7), pack-reused 46\u001b[K\n",
            "Unpacking objects: 100% (76/76), done.\n",
            "/content/sadc-movie-recommender\n",
            "Branch 'ui-changes' set up to track remote branch 'ui-changes' from 'origin'.\n",
            "Switched to a new branch 'ui-changes'\n",
            "/content/sadc-movie-recommender/rnn_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python3 train.py"
      ],
      "metadata": {
        "id": "6DNzSMmj_GOl",
        "outputId": "e879081a-31b1-4900-a7a6-b078f0648b0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aaaaaaaaaaaaaaaaaaaaaaa [47, 800]\n",
            "tensor([47])\n",
            "tensor([[-0.0867, -0.0642, -0.1094,  ...,  0.0350, -0.0287, -0.0915]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "train.py:101: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
            "  torch.nn.utils.clip_grad_norm(rnn.parameters(), clip)\n",
            "aaaaaaaaaaaaaaaaaaaaaaa [2403, 2916, 2105, 1909, 1223, 2772, 2168, 2500, 2312, 1779, 543, 377, 953, 1982, 141, 3827]\n",
            "tensor([2403, 2916, 2105, 1909, 1223, 2772, 2168, 2500, 2312, 1779,  543,  377,\n",
            "         953, 1982,  141])\n",
            "tensor([[-0.7916, -0.7148, -0.7304,  ..., -0.6754, -0.6415, -0.7814],\n",
            "        [-0.8037, -0.6893, -0.7154,  ..., -0.6904, -0.6217, -0.7693],\n",
            "        [-0.8410, -0.6992, -0.7444,  ..., -0.7162, -0.6230, -0.7809],\n",
            "        ...,\n",
            "        [-0.8519, -0.7007, -0.7709,  ..., -0.7706, -0.6613, -0.7486],\n",
            "        [-0.8333, -0.7258, -0.7919,  ..., -0.7498, -0.6762, -0.7655],\n",
            "        [-0.8552, -0.7147, -0.8061,  ..., -0.7481, -0.6612, -0.7691]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 98, in <module>\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\", line 307, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 156, in backward\n",
            "    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
            "RuntimeError: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Overview of Colaboratory Features",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}